Project Structure:
├── __pycache__
│   ├── __init__.cpython-311.pyc
│   ├── __init__.cpython-38.pyc
│   ├── base_dataset.cpython-311.pyc
│   ├── base_dataset.cpython-38.pyc
│   ├── common_utils.cpython-311.pyc
│   └── common_utils.cpython-38.pyc
├── diode
│   ├── __pycache__
│   │   ├── __init__.cpython-311.pyc
│   │   ├── __init__.cpython-38.pyc
│   │   ├── dataset.cpython-311.pyc
│   │   └── dataset.cpython-38.pyc
│   ├── __init__.py
│   ├── dataset.py
│   └── diode.yaml
├── kitti
│   ├── __pycache__
│   │   ├── __init__.cpython-311.pyc
│   │   ├── __init__.cpython-38.pyc
│   │   ├── dataset.cpython-311.pyc
│   │   └── dataset.cpython-38.pyc
│   ├── __init__.py
│   ├── dataset.py
│   └── kitti.yaml
├── nyu
│   ├── __pycache__
│   │   ├── __init__.cpython-311.pyc
│   │   ├── __init__.cpython-38.pyc
│   │   ├── dataset.cpython-311.pyc
│   │   └── dataset.cpython-38.pyc
│   ├── __init__.py
│   ├── dataset.py
│   └── nyu.yaml
├── __init__.py
├── base_dataset.py
└── common_utils.py


File: base_dataset.py
from typing import Dict, List, Tuple, Optional
import torch
from torch.utils.data import Dataset
import yaml
import os
import numpy as np
from PIL import Image
from abc import ABC, abstractmethod
import torchvision.transforms as transforms

class BaseDataset(Dataset, ABC):
    """Base class for all datasets."""
    
    def __init__(self, config_path: str, split: str = 'test', batch_size: int = 1):
        """Initialize dataset.
        
        Args:
            config_path: Path to dataset config file
            split: Dataset split (train/val/test)
            batch_size: Batch size for loading data
        """
        super().__init__()
        self.batch_size = batch_size
        self.split = split
        
        # Load config
        with open(config_path, 'r') as f:
            self.config = yaml.safe_load(f)
            
        # Set paths from config
        self.root_dir = self.config['paths']['root_dir']
        
        self._check_downloaded()
        
        self.split_dir = os.path.join(self.root_dir, self.config['paths'][split])
        
        # Set transforms
        self.rgb_transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize(
                mean=self.config['preprocessing']['rgb_mean'],
                std=self.config['preprocessing']['rgb_std']
            )
        ])
        
        # Load dataset structure
        self.data_pairs = self._traverse_directory()
        
    @abstractmethod
    def _traverse_directory(self) -> List[Dict[str, str]]:
        """Traverse directory and get pairs of RGB and depth paths.
        
        Returns:
            List of dicts containing paths for image and depth pairs
        """
        pass
        
    def __len__(self) -> int:
        """Return total number of samples."""
        return len(self.data_pairs)
    
    def __getitem__(self, idx: int) -> Dict[str, torch.Tensor]:
        """Get a sample from the dataset.
        
        Args:
            idx: Sample index
        
        Returns:
            Dict containing:
                - rgb: RGB image tensor [3, H, W]
                - depth: Depth map tensor [1, H, W]  
                - mask: Valid depth mask [1, H, W]
        """
        sample = self.data_pairs[idx]
        
        # Load RGB image
        # rgb = Image.open(sample['rgb']).convert('RGB')
        rgb = self._load_rgb_image(sample['rgb'])
        # Load depth map
        depth = self._load_depth(sample['depth'])
        if not torch.is_tensor(depth):
            depth = torch.from_numpy(depth)
        
        # Create valid mask
        mask = self._get_valid_mask(depth)
        
        # Apply transformations
        # rgb = self.rgb_transform(rgb)
        # mask = torch.from_numpy(mask).float().unsqueeze(0)
        
        return {
            'rgb': rgb,
            'depth': depth,
            'mask': mask,
            'rgb_path': sample['rgb'],
            'depth_path': sample['depth']
        }
    
    @abstractmethod
    def _load_depth(self, path: str) -> np.ndarray:
        """Load depth map from file.
        
        Args:
            path: Path to depth map file
            
        Returns:
            Depth map as numpy array [H, W]
        """
        depth = Image.open(path)  # [H, W, rgb]
        depth = np.asarray(depth)
        return depth
    
    def _get_valid_mask(self, depth: torch.Tensor) -> torch.Tensor:
        valid_mask = torch.logical_and(
            (depth > self.min_depth), (depth < self.max_depth)
        ).bool()
        return valid_mask
    
    @abstractmethod
    def _download(self):
        """Download dataset files. Must be implemented by child classes."""
        pass
    
    def _check_downloaded(self):
        """Ensures dataset is downloaded. Called before directory traversal."""
        if not os.path.exists(self.root_dir) or len(os.listdir(self.root_dir)) == 0:
            print(f"Dataset not found in {self.root_dir}, downloading...")
            self._download()
            
        if not os.path.exists(self.root_dir) or len(os.listdir(self.root_dir)) == 0:
            raise RuntimeError(f"Failed to download dataset to {self.root_dir}")
    
    def get_batch(self, start_idx: int) -> Tuple[Dict[str, torch.Tensor], int]:
        """Get a batch of samples.
        
        Args:
            start_idx: Starting index
            
        Returns:
            Batch of samples and next start index
        """
        batch_size = min(self.batch_size, len(self) - start_idx)
        batch = {
            'rgb': [],
            'depth': [],
            'mask': [],
            'rgb_path': [],
            'depth_path': []
        }
        
        for i in range(batch_size):
            sample = self[start_idx + i]
            for key in batch:
                batch[key].append(sample[key])
                
        # Stack tensors
        for key in ['rgb', 'depth', 'mask']:
            batch[key] = torch.stack(batch[key])
            
        return batch, start_idx + batch_size

# Dictionary to register dataset classes
DATASET_REGISTRY = {}

def register_dataset(name: str):
    """Decorator to register a new dataset class."""
    def wrapper(cls):
        DATASET_REGISTRY[name] = cls
        return cls
    return wrapper

File: common_utils.py
import urllib.request
import tqdm
import os
import tarfile
import shutil


def download_with_progress(url: str, destination: str):
    """Download file with progress bar."""
    response = urllib.request.urlopen(url)
    total_size = int(response.headers.get("content-length", 0))

    with tqdm.tqdm(
        total=total_size, unit="B", unit_scale=True, desc=os.path.basename(destination)
    ) as pbar:
        urllib.request.urlretrieve(
            url,
            destination,
            reporthook=lambda count, block_size, total_size: pbar.update(block_size),
        )


def extract_tarfile(tar_path: str, extract_path: str):
    """Extract tar file with progress bar."""
    with tarfile.open(tar_path) as tar:
        members = tar.getmembers()
        with tqdm.tqdm(total=len(members), desc="Extracting") as pbar:
            for member in members:
                tar.extract(member, path=extract_path)
                pbar.update(1)


def download_and_extract(
    url: str, download_dir: str, extract_dir: str, remove_tar: bool = True
):
    """Download and extract a tar file."""
    os.makedirs(download_dir, exist_ok=True)

    # Get filename from URL
    filename = os.path.basename(url).split("?")[0]  # Remove URL parameters
    tar_path = os.path.join(download_dir, filename)

    # Download if doesn't exist
    if not os.path.exists(tar_path):
        print(f"Downloading {filename}...")
        download_with_progress(url, tar_path)

    # Extract
    print(f"Extracting {filename}...")
    with tarfile.open(tar_path) as tar:
        members = tar.getmembers()
        with tqdm.tqdm(total=len(members), desc="Extracting") as pbar:
            for member in members:
                tar.extract(member, path=extract_dir)
                pbar.update(1)

    # Clean up
    if remove_tar:
        os.remove(tar_path)


File: __init__.py
from .base_dataset import BaseDataset, DATASET_REGISTRY
from .nyu import NYUDataset
from .mock_dataset import MockDataset
from .kitti import KITTIDataset
from .diode import DIODEDataset
from .eth3d import ETH3DDataset
from .synth2 import Synth2Dataset


def build_dataset(name: str, config_path: str, **kwargs):
    """Build a dataset by name."""
    if name not in DATASET_REGISTRY:
        raise ValueError(f"Unknown dataset: {name}")
        
    return DATASET_REGISTRY[name](config_path, **kwargs)

__all__ = [
    'BaseDataset',
    'NYUDataset',
    'MockDataset',
    'build_dataset',
    'DATASET_REGISTRY',
    'KITTIDataset',
    'DIODEDataset',
    'ETH3DDataset',
    'Synth2Dataset'
]

File: kitti/__init__.py
from .dataset import KITTIDataset

__all__ = ['KITTIDataset']

File: kitti/dataset.py
import os
import numpy as np
from PIL import Image
from typing import Dict, List, Optional
import skimage
import time
import scipy
import torch
from ..base_dataset import BaseDataset, register_dataset
from ..common_utils import download_and_extract

def fill_depth_colorization(imgRgb=None, imgDepthInput=None, alpha=1):
    """Interpolate sparse depth map using colorization method."""
    imgIsNoise = imgDepthInput == 0
    maxImgAbsDepth = np.max(imgDepthInput)
    imgDepth = imgDepthInput / maxImgAbsDepth
    imgDepth[imgDepth > 1] = 1
    (H, W) = imgDepth.shape
    numPix = H * W
    indsM = np.arange(numPix).reshape((W, H)).transpose()
    knownValMask = (imgIsNoise == False).astype(int)
    grayImg = skimage.color.rgb2gray(imgRgb)
    winRad = 1
    len_ = 0
    absImgNdx = 0
    len_window = (2 * winRad + 1) ** 2
    len_zeros = numPix * len_window

    cols = np.zeros(len_zeros) - 1
    rows = np.zeros(len_zeros) - 1
    vals = np.zeros(len_zeros) - 1
    gvals = np.zeros(len_window) - 1

    for j in range(W):
        for i in range(H):
            nWin = 0
            for ii in range(max(0, i - winRad), min(i + winRad + 1, H)):
                for jj in range(max(0, j - winRad), min(j + winRad + 1, W)):
                    if ii == i and jj == j:
                        continue

                    rows[len_] = absImgNdx
                    cols[len_] = indsM[ii, jj]
                    gvals[nWin] = grayImg[ii, jj]

                    len_ = len_ + 1
                    nWin = nWin + 1

            curVal = grayImg[i, j]
            gvals[nWin] = curVal
            c_var = np.mean((gvals[:nWin + 1] - np.mean(gvals[:nWin+ 1])) ** 2)

            csig = c_var * 0.6
            mgv = np.min((gvals[:nWin] - curVal) ** 2)
            if csig < -mgv / np.log(0.01):
                csig = -mgv / np.log(0.01)

            if csig < 2e-06:
                csig = 2e-06

            gvals[:nWin] = np.exp(-(gvals[:nWin] - curVal) ** 2 / csig)
            gvals[:nWin] = gvals[:nWin] / sum(gvals[:nWin])
            vals[len_ - nWin:len_] = -gvals[:nWin]

            rows[len_] = absImgNdx
            cols[len_] = absImgNdx
            vals[len_] = 1

            len_ = len_ + 1
            absImgNdx = absImgNdx + 1

    vals = vals[:len_]
    cols = cols[:len_]
    rows = rows[:len_]
    A = scipy.sparse.csr_matrix((vals, (rows, cols)), (numPix, numPix))

    rows = np.arange(0, numPix)
    cols = np.arange(0, numPix)
    vals = (knownValMask * alpha).transpose().reshape(numPix)
    G = scipy.sparse.csr_matrix((vals, (rows, cols)), (numPix, numPix))

    A = A + G
    b = np.multiply(vals.reshape(numPix), imgDepth.flatten('F'))

    new_vals = scipy.sparse.linalg.spsolve(A, b)
    new_vals = np.reshape(new_vals, (H, W), 'F')

    denoisedDepthImg = new_vals * maxImgAbsDepth
    
    output = denoisedDepthImg.reshape((H, W)).astype('float32')
    output = np.multiply(output, (1-knownValMask)) + imgDepthInput
    
    return output

def kitti_benchmark_crop(input_img):
    """
    Crop images to KITTI benchmark size
    Args:
        `input_img` (torch.Tensor): Input image to be cropped.

    Returns:
        torch.Tensor:Cropped image.
    """
    KB_CROP_HEIGHT = 352
    KB_CROP_WIDTH = 1216
    height, width = input_img.shape[-2:]
    top_margin = int(height - KB_CROP_HEIGHT)
    left_margin = int((width - KB_CROP_WIDTH) / 2)
    if 2 == len(input_img.shape):
        out = input_img[
            top_margin : top_margin + KB_CROP_HEIGHT,
            left_margin : left_margin + KB_CROP_WIDTH,
        ]
    elif 3 == len(input_img.shape):
        out = input_img[
            :,
            top_margin : top_margin + KB_CROP_HEIGHT,
            left_margin : left_margin + KB_CROP_WIDTH,
        ]
    return out


@register_dataset('kitti')
class KITTIDataset(BaseDataset):
    """KITTI depth dataset."""
    min_depth=1e-5
    max_depth=80.0
    
    
    def _traverse_directory(self) -> List[Dict[str, str]]:
        """Find all matching RGB-D pairs in the dataset.

        Returns:
            List[Dict[str, str]]: List of dictionaries containing paired 'rgb' and 'depth' file paths
        """
        data_pairs = []

        # Iterate through drive dates
        for drive_date in os.listdir(self.root_dir):
            if drive_date.endswith("sync"):
                continue

            date_path = os.path.join(self.root_dir, drive_date)

            # Iterate through drive numbers
            for drive_num in os.listdir(date_path):
                rgb_dir = os.path.join(date_path, drive_num, "image_02", "data")
                depth_dir = os.path.join(
                    self.root_dir, drive_num, "proj_depth/groundtruth/image_02"
                )

                # Skip if RGB directory doesn't exist
                if not os.path.exists(rgb_dir):
                    continue

                # Get all RGB images
                for img_name in os.listdir(rgb_dir):
                    if not img_name.endswith(".png"):
                        continue

                    rgb_path = os.path.join(rgb_dir, img_name)
                    depth_path = os.path.join(depth_dir, img_name)

                    # Verify both files exist
                    try:
                        # Quick verification that depth file can be opened
                        Image.open(depth_path)

                        # Add valid pair to dataset
                        data_pairs.append({"rgb": rgb_path, "depth": depth_path})
                    except (FileNotFoundError, IOError):
                        continue

        return sorted(data_pairs, key=lambda x: x["rgb"])

    
    
    def _load_depth(self, path: str) -> np.ndarray:
        """Load KITTI depth map.
        
        KITTI depth maps are uint16 PNGs with depth values
        encoded in the actual pixel values.
        """
        depth = np.asarray(Image.open(path)).squeeze()
        depth = depth / 256.0
        depth = torch.from_numpy(depth).float().unsqueeze(0)
        depth_crop = kitti_benchmark_crop(depth)
                    
        return depth_crop
    
    def _get_valid_mask(self, depth: torch.Tensor, valid_mask_crop="eigen"):
        # reference: https://github.com/cleinc/bts/blob/master/pytorch/bts_eval.py
        valid_mask = super()._get_valid_mask(depth)
        if valid_mask_crop is not None:
            eval_mask = torch.zeros_like(valid_mask.squeeze()).bool()
            print('eval_mask.shape', eval_mask.shape)
            gt_height, gt_width = eval_mask.shape

            if "garg" == valid_mask_crop:
                eval_mask[
                    int(0.40810811 * gt_height) : int(0.99189189 * gt_height),
                    int(0.03594771 * gt_width) : int(0.96405229 * gt_width),
                ] = 1
            elif "eigen" == valid_mask_crop:
                eval_mask[
                    int(0.3324324 * gt_height) : int(0.91351351 * gt_height),
                    int(0.0359477 * gt_width) : int(0.96405229 * gt_width),
                ] = 1

            eval_mask.reshape(valid_mask.shape)
            valid_mask = torch.logical_and(valid_mask, eval_mask)
        return valid_mask
    
    def _load_rgb_image(self, path:str) -> torch.Tensor:
        rgb = np.array(Image.open(path))
        rgb_torch = torch.from_numpy(rgb).permute(2, 0, 1)#[:3,:,:]
        return kitti_benchmark_crop(rgb_torch)
    
    def _download(self):
        """Download and extract KITTI dataset if not already present."""
        # Check if data already exists
        if os.path.exists(self.root_dir) and len(os.listdir(self.root_dir)) > 0:
            print("KITTI dataset already exists.")
            return

        url = "https://huggingface.co/datasets/guangkaixu/genpercept_datasets_eval/resolve/main/eval_kitti_genpercept.tar.gz?download=true"
        print("Downloading KITTI dataset...")
        download_and_extract(
            url=url,
            download_dir=os.path.dirname(self.root_dir),
            extract_dir=os.path.dirname(self.root_dir),
        )
    

File: diode/__init__.py
from .dataset import DIODEDataset

__all__ = ['DIODEDataset']

File: diode/dataset.py
import os
import numpy as np
from PIL import Image
import torch
import torch.nn.functional as F
from typing import Dict, List
from ..base_dataset import BaseDataset, register_dataset
from ..common_utils import download_and_extract

@register_dataset('diode')
class DIODEDataset(BaseDataset):
    """DIODE depth dataset."""
    
    def __init__(self, config_path: str, split: str = 'val', batch_size: int = 1):
        """Initialize DIODE dataset."""
        super().__init__(config_path, split, batch_size)
        self.min_depth=0.6
        self.max_depth=350.0

    
    def _traverse_directory(self) -> List[Dict[str, str]]:
        """Find all matching RGB-D pairs in the dataset."""
        data_pairs = []

        for env_type in ["indoors", "outdoors"]:
            env_path = os.path.join(self.root_dir, env_type)
            if not os.path.exists(env_path):
                continue

            for scene_dir in sorted(os.listdir(env_path)):
                scene_path = os.path.join(env_path, scene_dir)
                if not os.path.isdir(scene_path):
                    continue

                for scan_dir in sorted(os.listdir(scene_path)):
                    scan_path = os.path.join(scene_path, scan_dir)
                    if not os.path.isdir(scan_path):
                        continue

                    for filename in sorted(os.listdir(scan_path)):
                        if not filename.endswith(".png") or "_depth_mask" in filename:
                            continue

                        base_name = filename[:-4]
                        rgb_path = os.path.join(scan_path, f"{base_name}.png")
                        depth_path = os.path.join(scan_path, f"{base_name}_depth.npy")
                        mask_path = os.path.join(
                            scan_path, f"{base_name}_depth_mask.npy"
                        )

                        if (
                            os.path.exists(rgb_path)
                            and os.path.exists(depth_path)
                            and os.path.exists(mask_path)
                        ):
                            data_pairs.append(
                                {
                                    "rgb": rgb_path,
                                    "depth": depth_path,
                                    "mask": mask_path,
                                }
                            )

        return sorted(data_pairs, key=lambda x: x["rgb"])

    
    def _load_depth(self, path: str) -> np.ndarray:
        """Load DIODE depth map from .npy file."""
        try:
            # Load depth map
            depth = np.load(path).squeeze()[np.newaxis, :, :].squeeze()
            depth = torch.from_numpy(depth).float().unsqueeze(0) 
                
            return depth
            
        except Exception as e:
            print(f"Error loading depth from {path}: {str(e)}")
            return np.zeros((768, 1024), dtype=np.float32)
        
    def _get_valid_mask(self, path: str):
        # reference: https://github.com/cleinc/bts/blob/master/pytorch/bts_eval.py
        mask_path = path.replace('_depth.npy', '_depth_mask.npy')
        valid_mask = np.load(mask_path).squeeze()[np.newaxis, :, :].squeeze()
        valid_mask = torch.from_numpy(valid_mask).unsqueeze(0).bool()
        
        return valid_mask
            
    def _resize_depth_and_mask(self, depth: np.ndarray, target_size: tuple) -> tuple:
        """Resize depth map and create corresponding mask using proper interpolation."""
        # Convert to torch tensor and add batch and channel dimensions
        depth_tensor = torch.from_numpy(depth).float().unsqueeze(0).unsqueeze(0)
        
        # Resize depth map
        resized_depth = F.interpolate(
            depth_tensor,
            size=target_size,
            mode='bicubic',
            align_corners=True
        ).squeeze()
        
        # Create mask from resized depth
        resized_mask = (resized_depth > 0).float()
        
        return resized_depth.numpy(), resized_mask.numpy()
    
    def _load_rgb_image(self, path:str) -> torch.Tensor:
        rgb = np.array(Image.open(path))
        rgb_torch = torch.from_numpy(rgb).permute(2, 0, 1)#[:3,:,:]
        return rgb_torch

    def __getitem__(self, idx: int) -> Dict[str, torch.Tensor]:
        """Get a sample from the dataset."""
        sample = self.data_pairs[idx]
        
        # Load RGB image
        # rgb = Image.open(sample['rgb']).convert('RGB')
        rgb = self._load_rgb_image(sample['rgb'])
        # Load depth map
        depth = self._load_depth(sample['depth'])
        if not torch.is_tensor(depth):
            depth = torch.from_numpy(depth)
        
        # Create valid mask
        mask = self._get_valid_mask(sample['depth'])
                
        return {
            'rgb': rgb,
            'depth': depth,
            'mask': mask,
            'rgb_path': sample['rgb'],
            'depth_path': sample['depth']
        }
        
    def _download(self):
        """Download and extract DIODE dataset if not already present."""
        # Check if data already exists
        if os.path.exists(self.root_dir) and len(os.listdir(self.root_dir)) > 0:
            print("DIODE dataset already exists.")
            return

        url = "https://huggingface.co/datasets/guangkaixu/genpercept_datasets_eval/resolve/main/eval_diode_genpercept.tar.gz?download=true"
        print("Downloading DIODE dataset...")
        download_and_extract(
            url=url,
            download_dir=os.path.dirname(self.root_dir),
            extract_dir=os.path.dirname(self.root_dir),
        )

File: nyu/__init__.py
from .dataset import NYUDataset

__all__ = ['NYUDataset']

File: nyu/dataset.py
import os
import numpy as np
import torch
from PIL import Image
from typing import Dict, List

from ..base_dataset import BaseDataset, register_dataset
from ..common_utils import download_and_extract

@register_dataset('nyu')
class NYUDataset(BaseDataset):
    """NYU Depth V2 dataset."""
    min_depth = 1e-3
    max_depth = 10.0
    
    
    def _traverse_directory(self) -> List[Dict[str, str]]:
        """Traverse NYU dataset directory structure."""
        data_pairs = []
        split_dir = os.path.join(self.root_dir, self.split)

        if not os.path.exists(split_dir):
            print(f"Split directory does not exist: {split_dir}")
            return data_pairs

        for scene in os.listdir(split_dir):
            scene_dir = os.path.join(split_dir, scene)
            if not os.path.isdir(scene_dir):
                continue

            rgb_files = [
                f for f in os.listdir(scene_dir)
                if f.startswith("rgb_") and f.endswith(".png")
            ]

            for rgb_file in rgb_files:
                img_id = rgb_file.replace("rgb_", "").replace(".png", "")
                depth_file = f"depth_{img_id}.png"

                rgb_path = os.path.join(scene_dir, rgb_file)
                depth_path = os.path.join(scene_dir, depth_file)

                if os.path.exists(rgb_path) and os.path.exists(depth_path):
                    data_pairs.append({"rgb": rgb_path, "depth": depth_path})

        return sorted(data_pairs, key=lambda x: x["rgb"])

        
    def _load_depth(self, path: str) -> np.ndarray:
        """Load NYU depth map.
        
        Args:
            path: Path to depth map file
            
        Returns:
            Depth map as numpy array [H, W]
        """
        # Load depth (NYU depths are in millimeters)
        depth = super()._load_depth(path)
        depth = depth.astype(np.float32) / 1000.0
        # Normalize
        
        return depth
    
    def _load_rgb_image(self, path:str) -> torch.Tensor:
        rgb = np.array(Image.open(path))
        rgb_torch = torch.from_numpy(rgb).permute(2, 0, 1)#[:3,:,:]
        return rgb_torch
    
    def _get_valid_mask(self, depth: torch.Tensor) -> torch.Tensor:
        valid_mask = super()._get_valid_mask(depth)
        eval_mask = torch.zeros_like(valid_mask.squeeze()).bool()
        eval_mask[45:471, 41:601] = 1
        eval_mask.reshape(valid_mask.shape)
        valid_mask = torch.logical_and(valid_mask, eval_mask)
        
        return valid_mask
    
    def _download(self):
        """Download and extract NYU dataset if not already present."""
        if os.path.exists(self.root_dir) and len(os.listdir(self.root_dir)) > 0:
            print("NYU dataset already exists.")
            return

        url = "https://huggingface.co/datasets/guangkaixu/genpercept_datasets_eval/resolve/main/eval_nyu_genpercept.tar.gz?download=true"
        print("Downloading NYU dataset...")
        download_and_extract(
            url=url,
            download_dir=os.path.dirname(self.root_dir),
            extract_dir=os.path.dirname(self.root_dir)
        )
        
